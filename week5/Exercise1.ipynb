{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global registration with RANSAC\n",
    "We are going to use open3d (http://www.open3d.org/) to handle  pointclouds and generation of pointclouds\n",
    "\n",
    "So make sure to call **pip install open3d**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "# helper function for drawing if you want it to be more clear which is which set recolor=True\n",
    "def draw_registrations(source, target, transformation = None, recolor = False):\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    if(recolor):\n",
    "        source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "        target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    if(transformation is not None):\n",
    "        source_temp.transform(transformation)\n",
    "    o3d.visualization.draw_geometries([source_temp, target_temp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to read in our pointclouds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = o3d.io.read_point_cloud(\"ICP/r1.pcd\")\n",
    "#target = o3d.io.read_point_cloud(\"ICP/r2.pcd\")\n",
    "target = o3d.io.read_point_cloud(\"ICP/r3.pcd\")\n",
    "\n",
    "# Show models side by side\n",
    "draw_registrations(source, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding features in pointclouds\n",
    "When working on point clouds it can be benefitial work on a downsampled version of the point cloud.\n",
    "you can use [```pointcloudname.voxel_down_sample()```](http://www.open3d.org/docs/latest/python_api/open3d.geometry.PointCloud.html) where pointcloud is the name of your point cloud object.\n",
    "\n",
    "We also need to estimate the normals of the pointcloud points using [```pointcloudname.estimate_normals()```](http://www.open3d.org/docs/latest/python_api/open3d.geometry.PointCloud.html)\n",
    "\n",
    "And finally find fpfh features or correspondance of the downsampled point clouds.\n",
    "[```o3d.registration.compute_fpfh_feature()```](http://www.open3d.org/docs/latest/python_api/open3d.registration.compute_fpfh_feature.html#open3d.registration.compute_fpfh_feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxel_size=0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_point_cloud(pcd, voxel_size):\n",
    "    print(\":: Downsample with a voxel size %.3f.\" % voxel_size)\n",
    "    pcd_down = pcd.voxel_down_sample(voxel_size)\n",
    "\n",
    "    radius_normal = voxel_size * 2\n",
    "    print(\":: Estimate normal with search radius %.3f.\" % radius_normal)\n",
    "    pcd_down.estimate_normals(\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_normal, max_nn=30))\n",
    "\n",
    "    radius_feature = voxel_size * 5\n",
    "    print(\":: Compute FPFH feature with search radius %.3f.\" % radius_feature)\n",
    "    pcd_fpfh = o3d.registration.compute_fpfh_feature(\n",
    "        pcd_down,\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_feature, max_nn=100))\n",
    "    return pcd_down, pcd_fpfh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": ":: Downsample with a voxel size 0.200.\n:: Estimate normal with search radius 0.400.\n:: Compute FPFH feature with search radius 1.000.\n:: Downsample with a voxel size 0.200.\n:: Estimate normal with search radius 0.400.\n:: Compute FPFH feature with search radius 1.000.\n"
    }
   ],
   "source": [
    "# Used for downsampling.\n",
    "voxel_size=0.05 #越大越稀疏\n",
    "\n",
    "source_down,source_fpfh = preprocess_point_cloud(source,voxel_size)\n",
    "target_down, target_fpfh = preprocess_point_cloud(target,voxel_size)\n",
    "draw_registrations(source_down, target_down,recolor = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ransac\n",
    "We will now attempt to use ransac to do a global registration of the two poinclouds.\n",
    "\n",
    "Using the function [```o3d.registration.registration_ransac_based_on_feature_matching```](http://www.open3d.org/docs/latest/python_api/open3d.registration.registration_ransac_based_on_feature_matching.html#open3d.registration.registration_ransac_based_on_feature_matching) from open3d\n",
    "\n",
    "\n",
    "Try to find the transformation from r1 to r2.\n",
    "Attempt with point to point and point to plane\n",
    "```Python\n",
    "point_to_point =  o3d.registration.TransformationEstimationPointToPoint(False)\n",
    "point_to_plane =  o3d.registration.TransformationEstimationPointToPlane()\n",
    "```\n",
    "\n",
    "When using ransac focus on the arguments below the rest are optional\n",
    "```Python\n",
    "ransac_result = o3d.registration.registration_ransac_based_on_feature_matching(\n",
    "    source_sample, target_sample, \n",
    "    source_fpfh, target_fpfh, \n",
    "    distance_threshold,\n",
    "    point_to_point)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\t\n",
    "def execute_global_registration(source_down, target_down, source_fpfh,\n",
    "                                target_fpfh, voxel_size):\n",
    "    distance_threshold = voxel_size * 1.5\n",
    "    print(\":: RANSAC registration on downsampled point clouds.\")\n",
    "    print(\"   Since the downsampling voxel size is %.3f,\" % voxel_size)\n",
    "    print(\"   we use a liberal distance threshold %.3f.\" % distance_threshold)\n",
    "\n",
    "    point_to_point =  o3d.registration.TransformationEstimationPointToPoint(False)\n",
    "    point_to_plane =  o3d.registration.TransformationEstimationPointToPlane()\n",
    "\n",
    "    corr_length = 0.9\n",
    "    distance_threshold = voxel_size * 1.5\n",
    "\n",
    "    c0 = o3d.registration.CorrespondenceCheckerBasedOnEdgeLength(corr_length)\n",
    "    c1 = o3d.registration.CorrespondenceCheckerBasedOnDistance(distance_threshold)\n",
    "    c2 = o3d.registration.CorrespondenceCheckerBasedOnNormal(0.095)\n",
    "\n",
    "    checker_list = [c0,c1,c2]\n",
    "\n",
    "    result = o3d.registration.registration_ransac_based_on_feature_matching(\n",
    "        source_down, target_down, \n",
    "        source_fpfh, target_fpfh,\n",
    "        distance_threshold,\n",
    "        point_to_point,\n",
    "        #point_to_plane,\n",
    "        checkers = checker_list)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": ":: RANSAC registration on downsampled point clouds.\n   Since the downsampling voxel size is 0.050,\n   we use a liberal distance threshold 0.075.\n"
    }
   ],
   "source": [
    "result_ransac = execute_global_registration(source_down, target_down, source_fpfh,target_fpfh, voxel_size=0.05)\n",
    "\n",
    "draw_registrations(source_down, target_down, transformation = result_ransac.transformation, recolor = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "### A)\n",
    "    Can you get a decent transformation from r1 to r3?\n",
    "### B)\n",
    "    with the following checkers can you get better results from RANSAC? \n",
    "    Try tweaking the parameters of them Can you make Point to Plane work do not spend too long on this if you cant skip it. (I was not able to get a good fit)\n",
    "\n",
    "You can also try tweaking the voxel_size\n",
    "```Python\n",
    "corr_length = 0.9\n",
    "distance_threshold = voxel_size * 1.5\n",
    "\n",
    "c0 = o3d.registration.CorrespondenceCheckerBasedOnEdgeLength(corr_length)\n",
    "c1 = o3d.registration.CorrespondenceCheckerBasedOnDistance(distance_threshold)\n",
    "c2 = o3d.registration.CorrespondenceCheckerBasedOnNormal(0.095)\n",
    "\n",
    "cecker_list = [c0,c1,c2]\n",
    "\n",
    "ransac_result = o3d.registration.registration_ransac_based_on_feature_matching(\n",
    "    source_sample, target_sample, \n",
    "    source_fpfh, target_fpfh, \n",
    "    distance_threshold,\n",
    "    point_to_point\n",
    "    checkers = checker_list)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}